{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import IPython\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import ConversationalRetrievalChain, RetrievalQAWithSourcesChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "# explicitly set the API key for embedding\n",
    "import openai\n",
    "openai.api_base = os.environ['OPENAI_API_BASE']\n",
    "openai.api_type = os.environ['OPENAI_API_TYPE']\n",
    "\n",
    "openai_api_base = os.environ['OPENAI_API_BASE']\n",
    "azure_development_name = os.environ['AZURE_DEVELOPMENT_NAME']\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import pdfminer\"\"\"\n",
    "from langchain.document_loaders import ReadTheDocsLoader, PyMuPDFLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "\n",
    "\n",
    "loader = PyMuPDFLoader(\"upload/Resume_Jesse_Chow.pdf\")\n",
    "raw_documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", chunk_size=1)\n",
    "db = FAISS.from_documents(documents, embeddings)\n",
    "resume_retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create job duties \n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "jd = \"\"\"\n",
    "\n",
    "Job duties of this Role:\n",
    "\n",
    "At the core of Accenture's Technology business, you are eager to learn and use that curiosity to solve technology problems through developing, designing and maintaining software products or systems that enable client strategies to improve the way our clients and the world works.\n",
    "\n",
    "You will be using your versatility and experience to create and support technology solutions that meet client requirements from analysis to implementation. The latest SDLC best practices will be applied to continuously improve the quality and efficiency of the Accenture development teams.\n",
    "\n",
    "Come JOIN US if you have:\n",
    "• Hands-on experience in application development and design on web applications that integrate to large scale/ mission critical systems using different technologies\n",
    "• Strong in Web (Responsive UI, Angular, React, JavaScript, HTML, CSS) Development\n",
    "• Knowledge on Redux and Saga is a plus\n",
    "• Interested to explore other technologies integration\n",
    "• Passionate and keen to develop your profession in technical delivery, and strive to deliver the best design, codes and practice\n",
    "• Excellent communication skill and the ability to interact professionally with diverse group of stakeholders, internally and externally\n",
    "• University Degree in Computer Science/Engineering, Information Technology/System, or other relevant disciplines desirable\n",
    "• High proficiency in both verbal and written English and Cantonese (Mandarin is an added advantage)\n",
    "• Dynamic and adaptive to the global collaborative project team environment\n",
    "• Candidates with more related experience can be considered as senior position\"\"\"\n",
    "\n",
    "\n",
    "jd_doc = Document(page_content=jd)\n",
    "split_doc = text_splitter.split_documents([jd_doc])\n",
    "job_db = FAISS.from_documents(split_doc, embeddings)\n",
    "job_retriever = job_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.memory import ConversationBufferMemory, ReadOnlySharedMemory\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# setup model in Azure Openai, and the model used to extract information from vectorstore\n",
    "\n",
    "\n",
    "\n",
    "# model using to extract information from vectorstore\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_base=openai_api_base,\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    deployment_name=azure_development_name,\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_api_type='azure',\n",
    "    temperature=0,\n",
    "    max_tokens=256\n",
    ")\n",
    "\n",
    "resume_prompt_template = \"\"\"Use the following pieces of context to provide information from the resume of the candidate to help rewrite the question to better assess the candidate.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "job_prompt_template = \"\"\"Use the following pieces of context to provide information of the job roles and duties to help rewrite the question to assess whether the candidate meets requirements included in the context.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "\n",
    "RESUME_PROMPT = PromptTemplate(\n",
    "    template=resume_prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "JOB_PROMPT = PromptTemplate(\n",
    "    template=job_prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "resume_chain_type_kwargs = {\"prompt\": RESUME_PROMPT}\n",
    "job_chain_type_kwargs = {\"prompt\": JOB_PROMPT}\n",
    "\n",
    "retriever = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=resume_retriever,\n",
    "    chain_type_kwargs=resume_chain_type_kwargs\n",
    ")\n",
    "\n",
    "jd_retriever = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=job_retriever,\n",
    "    chain_type_kwargs=job_chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"create tool\"\"\"\n",
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "\n",
    "tool_desc = \"\"\"Use this tool to create interview question related to skills and experience of the candidate. This tool can also be used for create follow up questions from candidate answers.\"\"\"\n",
    "\n",
    "jd_desc = \"\"\"Use this tool to provide information of the job position which the candidate applied to create interview question. This tool can also be used for create follow up questions from candidate answers.\"\"\"\n",
    "\n",
    "\n",
    "tools = [Tool(\n",
    "    func=retriever.run,\n",
    "    description=tool_desc,\n",
    "    name=\"resume\"\n",
    "), Tool(\n",
    "    func=jd_retriever.run,\n",
    "    description=jd_desc,\n",
    "    name=\"job_duties\"\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"FAKE chat history\"\"\"\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "memory.save_context(\n",
    "    {'input': \"hi\"},\n",
    "    {\"output\" : \"Goog morning, please introduce yourself.\",})\n",
    "memory.save_context(\n",
    "    {'input': 'I am Jesse Chow, have 100 year experience in software development.'},\n",
    "    {'output': \"That's good to hear. What is your current job title?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='hi', additional_kwargs={}, example=False), AIMessage(content='Goog morning, please introduce yourself.', additional_kwargs={}, example=False), HumanMessage(content='I am Jesse Chow, have 100 year experience in software development.', additional_kwargs={}, example=False), AIMessage(content=\"That's good to hear. What is your current job title?\", additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=False, human_prefix='Human', ai_prefix='AI', memory_key='chat_history')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"You are an experienced career coach. You are coaching a job seeker who just finished a job interview. Given the following Interview Record, AI as the interview and Human as the candidate. You should 3 actionable items for the candidate to improve in interview in point form. Your suggestions should directly refer to the interview record. You have access to the following tools:\"\"\"\n",
    "suffix = \"\"\"\n",
    "Interview Record:\n",
    "{chat_history}\n",
    "\n",
    "Begin! Refer to the interview record as you write your suggestions. Quote some of the interview record to support your suggestions. Remember, You are talking to the candidate who is the interviewee. Your response should not include the name of the tool you used. Your response should be in point form.\n",
    "\n",
    "Questions: {input}\n",
    "\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools=tools, \n",
    "    prefix=prefix, \n",
    "    suffix=suffix, \n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"]\n",
    ")\n",
    "\n",
    "\n",
    "model = AzureOpenAI(\n",
    "    openai_api_base=openai_api_base,\n",
    "    deployment_name=\"text-davinci-003\",\n",
    "    openai_api_key=openai_api_key,\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(llm=model, prompt=prompt)\n",
    "\n",
    "evaluate_agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(agent=evaluate_agent, tools=tools, verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to think about what the interviewer asked and what the candidate answered\n",
      "Action: resume\n",
      "Action Input: Jesse Chow's software development experience\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mWhat programming languages, web technologies, and databases is Jesse Chow proficient in, and what cloud services has he worked with? Can he provide examples of web applications and mobile apps he has developed using Next.js, React, Vue, and React Native, and what role did he play in their development? Additionally, can he describe his experience with backend API development using Nest.js, MongoDB, and MySQL, as well as his system design and DevOps experience with cloud services such as AWS and GCP?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know what the candidate needs to improve in the interview\n",
      "Final Answer: \n",
      "1. Prepare to answer questions about your software development experience in detail.\n",
      "2. Practice answering questions about the job duties and responsibilities of the position you applied for.\n",
      "3. Be prepared to provide examples of projects you have worked on and the role you played in their development.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1. Prepare to answer questions about your software development experience in detail.\\n2. Practice answering questions about the job duties and responsibilities of the position you applied for.\\n3. Be prepared to provide examples of projects you have worked on and the role you played in their development.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "agent_chain.run(input=\"Please give me 3 actionable items to increase my chance to get the job.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'redis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mredis\u001b[39;00m\n\u001b[1;32m      3\u001b[0m rs \u001b[39m=\u001b[39m redis\u001b[39m.\u001b[39mRedis(\u001b[39m\"\u001b[39m\u001b[39mredis://redis.internal.happyhill-5bfa4661.eastus.azurecontainerapps.io:6379\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'redis'"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "\n",
    "rs = redis.Redis(\"redis://redis.internal.happyhill-5bfa4661.eastus.azurecontainerapps.io:6379\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
